{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Patient Case Summary RAG Application\n",
    "\n",
    "This notebook contains a complete implementation of a Retrieval-Augmented Generation (RAG) application for generating patient case summaries. The application uses open-source tools to:\n",
    "\n",
    "1. Extract key details from patient data\n",
    "2. Retrieve relevant clinical guidelines\n",
    "3. Generate a comprehensive case summary with recommendations\n",
    "\n",
    "## Features\n",
    "\n",
    "- **Patient Data Processing**: Upload FHIR JSON files to extract patient information\n",
    "- **Medical Guidelines Management**: Add guidelines via text files or PDF files\n",
    "- **Case Summary Generation**: Generate comprehensive case summaries with recommendations\n",
    "- **Interactive Interface**: User-friendly interface for easy interaction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Install Required Packages\n",
    "\n",
    "First, let's install the necessary packages. You can skip this step if you already have these packages installed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.3.20)\n",
      "Requirement already satisfied: langchain-community in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.3.19)\n",
      "Requirement already satisfied: chromadb in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (0.6.3)\n",
      "Requirement already satisfied: pydantic in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (2.10.5)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (1.0.1)\n",
      "Requirement already satisfied: pypdf in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (5.3.1)\n",
      "Requirement already satisfied: ipywidgets in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (8.1.5)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.41 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (0.3.44)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.6 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (0.3.6)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (0.3.13)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (2.0.38)\n",
      "Requirement already satisfied: requests<3,>=2 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-community) (3.11.13)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-community) (2.8.1)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-community) (2.0.2)\n",
      "Requirement already satisfied: build>=1.0.3 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (1.2.2.post1)\n",
      "Requirement already satisfied: chroma-hnswlib==0.7.6 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (0.7.6)\n",
      "Requirement already satisfied: fastapi>=0.95.2 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (0.115.11)\n",
      "Requirement already satisfied: uvicorn>=0.18.3 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.34.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (3.19.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (4.12.2)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (1.21.0)\n",
      "Requirement already satisfied: opentelemetry-api>=1.2.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (1.30.0)\n",
      "Requirement already satisfied: tokenizers>=0.13.2 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (0.21.0)\n",
      "Requirement already satisfied: pypika>=0.48.9 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (0.48.9)\n",
      "Requirement already satisfied: tqdm>=4.65.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (4.67.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (7.7.0)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (6.5.2)\n",
      "Requirement already satisfied: grpcio>=1.58.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (1.69.0)\n",
      "Requirement already satisfied: bcrypt>=4.0.1 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (4.3.0)\n",
      "Requirement already satisfied: typer>=0.9.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (0.15.1)\n",
      "Requirement already satisfied: kubernetes>=28.1.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (32.0.1)\n",
      "Requirement already satisfied: mmh3>=4.0.1 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (5.1.0)\n",
      "Requirement already satisfied: orjson>=3.9.12 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (3.10.15)\n",
      "Requirement already satisfied: httpx>=0.27.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (0.28.1)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from chromadb) (13.9.4)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pydantic) (2.27.2)\n",
      "Requirement already satisfied: comm>=0.1.3 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipywidgets) (0.2.2)\n",
      "Requirement already satisfied: ipython>=6.1.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipywidgets) (8.31.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipywidgets) (5.14.3)\n",
      "Requirement already satisfied: widgetsnbextension~=4.0.12 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipywidgets) (4.0.13)\n",
      "Requirement already satisfied: jupyterlab-widgets~=3.0.12 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipywidgets) (3.0.13)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (24.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.1.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.18.3)\n",
      "Requirement already satisfied: packaging>=19.1 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from build>=1.0.3->chromadb) (24.2)\n",
      "Requirement already satisfied: pyproject_hooks in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from build>=1.0.3->chromadb) (1.2.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from build>=1.0.3->chromadb) (0.4.6)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from fastapi>=0.95.2->chromadb) (0.46.0)\n",
      "Requirement already satisfied: anyio in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.27.0->chromadb) (4.8.0)\n",
      "Requirement already satisfied: certifi in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.27.0->chromadb) (2024.12.14)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.27.0->chromadb) (1.0.7)\n",
      "Requirement already satisfied: idna in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpx>=0.27.0->chromadb) (3.10)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from httpcore==1.*->httpx>=0.27.0->chromadb) (0.14.0)\n",
      "Requirement already satisfied: decorator in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.19.2)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.1.7)\n",
      "Requirement already satisfied: prompt_toolkit<3.1.0,>=3.0.41 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (3.0.48)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (2.19.1)\n",
      "Requirement already satisfied: stack_data in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from ipython>=6.1.0->ipywidgets) (0.6.3)\n",
      "Requirement already satisfied: six>=1.9.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kubernetes>=28.1.0->chromadb) (1.17.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kubernetes>=28.1.0->chromadb) (2.9.0.post0)\n",
      "Requirement already satisfied: google-auth>=1.0.1 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kubernetes>=28.1.0->chromadb) (2.38.0)\n",
      "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kubernetes>=28.1.0->chromadb) (1.8.0)\n",
      "Requirement already satisfied: requests-oauthlib in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kubernetes>=28.1.0->chromadb) (2.0.0)\n",
      "Requirement already satisfied: oauthlib>=3.2.2 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kubernetes>=28.1.0->chromadb) (3.2.2)\n",
      "Requirement already satisfied: urllib3>=1.24.2 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kubernetes>=28.1.0->chromadb) (2.3.0)\n",
      "Requirement already satisfied: durationpy>=0.7 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from kubernetes>=28.1.0->chromadb) (0.9)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langchain-core<1.0.0,>=0.3.41->langchain) (1.33)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: coloredlogs in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from onnxruntime>=1.14.1->chromadb) (24.12.23)\n",
      "Requirement already satisfied: protobuf in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from onnxruntime>=1.14.1->chromadb) (5.29.3)\n",
      "Requirement already satisfied: sympy in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from onnxruntime>=1.14.1->chromadb) (1.13.1)\n",
      "Requirement already satisfied: deprecated>=1.2.6 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (1.2.18)\n",
      "Requirement already satisfied: importlib-metadata<=8.5.0,>=6.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from opentelemetry-api>=1.2.0->chromadb) (8.5.0)\n",
      "Requirement already satisfied: googleapis-common-protos~=1.52 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.69.1)\n",
      "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.30.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-proto==1.30.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb) (1.30.0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.51b0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-instrumentation==0.51b0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.51b0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: opentelemetry-util-http==0.51b0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (0.51b0)\n",
      "Requirement already satisfied: wrapt<2.0.0,>=1.0.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from opentelemetry-instrumentation==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (1.17.2)\n",
      "Requirement already satisfied: asgiref~=3.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from opentelemetry-instrumentation-asgi==0.51b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb) (3.8.1)\n",
      "Requirement already satisfied: monotonic>=1.5 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: distro>=1.5.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from posthog>=2.4.0->chromadb) (1.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from rich>=10.11.0->chromadb) (3.0.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from tokenizers>=0.13.2->chromadb) (0.27.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from typer>=0.9.0->chromadb) (8.1.8)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from typer>=0.9.0->chromadb) (1.5.4)\n",
      "Requirement already satisfied: httptools>=0.6.3 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.4)\n",
      "Requirement already satisfied: watchfiles>=0.13 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.4)\n",
      "Requirement already satisfied: websockets>=10.4 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from uvicorn[standard]>=0.18.3->chromadb) (15.0.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (5.5.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (4.9)\n",
      "Requirement already satisfied: filelock in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (3.16.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from huggingface-hub<1.0,>=0.16.4->tokenizers>=0.13.2->chromadb) (2024.12.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from importlib-metadata<=8.5.0,>=6.0->opentelemetry-api>=1.2.0->chromadb) (3.21.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets) (0.8.4)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.41->langchain) (3.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->chromadb) (0.1.2)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from prompt_toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets) (0.2.13)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from anyio->httpx>=0.27.0->chromadb) (1.3.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (2.1.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (3.0.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from stack_data->ipython>=6.1.0->ipywidgets) (0.2.3)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: pyreadline3 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime>=1.14.1->chromadb) (3.5.4)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\aryan\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.11_qbz5n2kfra8p0\\localcache\\local-packages\\python311\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain langchain-community chromadb pydantic python-dotenv pypdf ipywidgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Define Core Components\n",
    "\n",
    "### 2.1 Patient Data Parser\n",
    "\n",
    "This component extracts patient information from FHIR bundles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class ConditionInfo(BaseModel):\n",
    "    code: str\n",
    "    display: str\n",
    "    clinical_status: str\n",
    "\n",
    "class EncounterInfo(BaseModel):\n",
    "    date: str = Field(..., description=\"Date of the encounter.\")\n",
    "    reason_display: Optional[str] = Field(None, description=\"Reason for the encounter.\")\n",
    "    type_display: Optional[str] = Field(None, description=\"Type or class of the encounter.\")\n",
    "\n",
    "class MedicationInfo(BaseModel):\n",
    "    name: str = Field(..., description=\"Name of the medication.\")\n",
    "    start_date: Optional[str] = Field(None, description=\"When the medication was prescribed.\")\n",
    "    instructions: Optional[str] = Field(None, description=\"Dosage instructions.\")\n",
    "\n",
    "class PatientInfo(BaseModel):\n",
    "    given_name: str\n",
    "    family_name: str\n",
    "    birth_date: str\n",
    "    gender: str\n",
    "    conditions: List[ConditionInfo] = Field(default_factory=list)\n",
    "    recent_encounters: List[EncounterInfo] = Field(default_factory=list, description=\"A few recent encounters.\")\n",
    "    current_medications: List[MedicationInfo] = Field(default_factory=list, description=\"Current active medications.\")\n",
    "\n",
    "    @property\n",
    "    def demographic_str(self) -> str:\n",
    "        \"\"\"Get demographics string.\"\"\"\n",
    "        return f\"\"\"\\\n",
    "Given name: {self.given_name}\n",
    "Family name: {self.family_name}\n",
    "Birth date: {self.birth_date}\n",
    "Gender: {self.gender}\"\"\"\n",
    "\n",
    "\n",
    "def parse_synthea_patient(file_path: str, filter_active: bool = True) -> PatientInfo:\n",
    "    \"\"\"\n",
    "    Parse a Synthea-generated FHIR Bundle to extract patient information.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the JSON file containing the FHIR Bundle\n",
    "        filter_active: Whether to filter for only active conditions\n",
    "        \n",
    "    Returns:\n",
    "        PatientInfo object containing extracted patient data\n",
    "    \"\"\"\n",
    "    # Load the Synthea-generated FHIR Bundle\n",
    "    with open(file_path, \"r\") as f:\n",
    "        bundle = json.load(f)\n",
    "\n",
    "    patient_resource = None\n",
    "    conditions = []\n",
    "    encounters = []\n",
    "    medication_requests = []\n",
    "\n",
    "    for entry in bundle.get(\"entry\", []):\n",
    "        resource = entry.get(\"resource\", {})\n",
    "        resource_type = resource.get(\"resourceType\")\n",
    "\n",
    "        if resource_type == \"Patient\":\n",
    "            patient_resource = resource\n",
    "        elif resource_type == \"Condition\":\n",
    "            conditions.append(resource)\n",
    "        elif resource_type == \"Encounter\":\n",
    "            encounters.append(resource)\n",
    "        elif resource_type == \"MedicationRequest\":\n",
    "            medication_requests.append(resource)\n",
    "\n",
    "    if not patient_resource:\n",
    "        raise ValueError(\"No Patient resource found in the provided file.\")\n",
    "\n",
    "    # Extract patient demographics\n",
    "    name_entry = patient_resource.get(\"name\", [{}])[0]\n",
    "    given_name = name_entry.get(\"given\", [\"\"])[0]\n",
    "    family_name = name_entry.get(\"family\", \"\")\n",
    "    birth_date = patient_resource.get(\"birthDate\", \"\")\n",
    "    gender = patient_resource.get(\"gender\", \"\")\n",
    "\n",
    "    # Create PatientInfo object\n",
    "    patient_info = PatientInfo(\n",
    "        given_name=given_name,\n",
    "        family_name=family_name,\n",
    "        birth_date=birth_date,\n",
    "        gender=gender\n",
    "    )\n",
    "\n",
    "    # Extract conditions\n",
    "    for condition in conditions:\n",
    "        clinical_status = condition.get(\"clinicalStatus\", {}).get(\"coding\", [{}])[0].get(\"code\", \"\")\n",
    "        \n",
    "        # Skip if not active and filter_active is True\n",
    "        if filter_active and clinical_status != \"active\":\n",
    "            continue\n",
    "            \n",
    "        code_entry = condition.get(\"code\", {}).get(\"coding\", [{}])[0]\n",
    "        code = code_entry.get(\"code\", \"\")\n",
    "        display = code_entry.get(\"display\", \"\")\n",
    "        \n",
    "        patient_info.conditions.append(\n",
    "            ConditionInfo(\n",
    "                code=code,\n",
    "                display=display,\n",
    "                clinical_status=clinical_status\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Extract recent encounters (sort by date, most recent first)\n",
    "    sorted_encounters = sorted(\n",
    "        encounters,\n",
    "        key=lambda e: e.get(\"period\", {}).get(\"start\", \"\"),\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    for encounter in sorted_encounters[:5]:  # Get 5 most recent encounters\n",
    "        period = encounter.get(\"period\", {})\n",
    "        date = period.get(\"start\", \"\")\n",
    "        \n",
    "        reason_display = \"\"\n",
    "        if encounter.get(\"reasonCode\"):\n",
    "            reason_display = encounter.get(\"reasonCode\", [{}])[0].get(\"coding\", [{}])[0].get(\"display\", \"\")\n",
    "        \n",
    "        type_display = \"\"\n",
    "        if encounter.get(\"type\"):\n",
    "            type_display = encounter.get(\"type\", [{}])[0].get(\"coding\", [{}])[0].get(\"display\", \"\")\n",
    "        \n",
    "        patient_info.recent_encounters.append(\n",
    "            EncounterInfo(\n",
    "                date=date,\n",
    "                reason_display=reason_display,\n",
    "                type_display=type_display\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Extract current medications\n",
    "    for med_request in medication_requests:\n",
    "        status = med_request.get(\"status\", \"\")\n",
    "        \n",
    "        # Skip if not active and filter_active is True\n",
    "        if filter_active and status != \"active\":\n",
    "            continue\n",
    "            \n",
    "        med_code_entry = med_request.get(\"medicationCodeableConcept\", {}).get(\"coding\", [{}])[0]\n",
    "        med_name = med_code_entry.get(\"display\", \"\")\n",
    "        \n",
    "        dosage_instruction = med_request.get(\"dosageInstruction\", [{}])[0]\n",
    "        text_instruction = dosage_instruction.get(\"text\", \"\")\n",
    "        \n",
    "        start_date = \"\"\n",
    "        if med_request.get(\"authoredOn\"):\n",
    "            start_date = med_request.get(\"authoredOn\", \"\")\n",
    "        \n",
    "        patient_info.current_medications.append(\n",
    "            MedicationInfo(\n",
    "                name=med_name,\n",
    "                start_date=start_date,\n",
    "                instructions=text_instruction\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return patient_info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 PDF Processor\n",
    "\n",
    "This component extracts text from PDF files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pypdf\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import tempfile\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"\n",
    "    Extract text from a PDF file.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        \n",
    "    Returns:\n",
    "        Extracted text as a string\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        # Open the PDF file\n",
    "        with open(pdf_path, 'rb') as file:\n",
    "            # Create a PDF reader object\n",
    "            pdf_reader = pypdf.PdfReader(file)\n",
    "            \n",
    "            # Extract text from each page\n",
    "            for page_num in range(len(pdf_reader.pages)):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                text += page.extract_text() + \"\\n\\n\"\n",
    "                \n",
    "        return text\n",
    "    except Exception as e:\n",
    "        print(f\"Error extracting text from PDF: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "def process_pdf_to_text_file(pdf_path, output_dir):\n",
    "    \"\"\"\n",
    "    Process a PDF file and save its text content to a text file.\n",
    "    \n",
    "    Args:\n",
    "        pdf_path: Path to the PDF file\n",
    "        output_dir: Directory to save the text file\n",
    "        \n",
    "    Returns:\n",
    "        Path to the created text file\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    # Extract text from PDF\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    if not text:\n",
    "        return None\n",
    "    \n",
    "    # Create output file path\n",
    "    pdf_filename = os.path.basename(pdf_path)\n",
    "    txt_filename = os.path.splitext(pdf_filename)[0] + \".txt\"\n",
    "    txt_path = os.path.join(output_dir, txt_filename)\n",
    "    \n",
    "    # Save text to file\n",
    "    with open(txt_path, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "    \n",
    "    return txt_path\n",
    "\n",
    "def process_pdfs_to_text(pdf_paths, output_dir):\n",
    "    \"\"\"\n",
    "    Process multiple PDF files and save their text content to text files.\n",
    "    \n",
    "    Args:\n",
    "        pdf_paths: List of paths to PDF files\n",
    "        output_dir: Directory to save the text files\n",
    "        \n",
    "    Returns:\n",
    "        List of paths to the created text files\n",
    "    \"\"\"\n",
    "    txt_paths = []\n",
    "    \n",
    "    for pdf_path in pdf_paths:\n",
    "        txt_path = process_pdf_to_text_file(pdf_path, output_dir)\n",
    "        if txt_path:\n",
    "            txt_paths.append(txt_path)\n",
    "    \n",
    "    return txt_paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Guideline Retriever\n",
    "\n",
    "This component handles the storage and retrieval of medical guidelines using a vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.schema import Document\n",
    "import os\n",
    "import chromadb\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "class SimpleEmbeddings:\n",
    "    \"\"\"\n",
    "    A simple embedding class that uses TF-IDF like approach for text embeddings.\n",
    "    This is a lightweight alternative that doesn't require external models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dimension=100):\n",
    "        \"\"\"Initialize with a fixed embedding dimension.\"\"\"\n",
    "        self.dimension = dimension\n",
    "        self.vocabulary = {}\n",
    "        self.vocab_size = 0\n",
    "        \n",
    "    def _preprocess_text(self, text):\n",
    "        \"\"\"Simple text preprocessing.\"\"\"\n",
    "        # Convert to lowercase and split by whitespace\n",
    "        return text.lower().split()\n",
    "        \n",
    "    def _update_vocabulary(self, tokens):\n",
    "        \"\"\"Update vocabulary with new tokens.\"\"\"\n",
    "        for token in tokens:\n",
    "            if token not in self.vocabulary:\n",
    "                self.vocabulary[token] = self.vocab_size\n",
    "                self.vocab_size += 1\n",
    "    \n",
    "    def _text_to_vector(self, text):\n",
    "        \"\"\"Convert text to a fixed-dimension vector.\"\"\"\n",
    "        tokens = self._preprocess_text(text)\n",
    "        self._update_vocabulary(tokens)\n",
    "        \n",
    "        # Create a simple frequency vector\n",
    "        vec = np.zeros(self.dimension)\n",
    "        for token in tokens:\n",
    "            if token in self.vocabulary:\n",
    "                # Use modulo to ensure we stay within dimension\n",
    "                idx = self.vocabulary[token] % self.dimension\n",
    "                vec[idx] += 1\n",
    "        \n",
    "        # Normalize the vector\n",
    "        norm = np.linalg.norm(vec)\n",
    "        if norm > 0:\n",
    "            vec = vec / norm\n",
    "        return vec\n",
    "    \n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Embed a list of documents.\"\"\"\n",
    "        return [self._text_to_vector(text).tolist() for text in texts]\n",
    "    \n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"Embed a query.\"\"\"\n",
    "        return self._text_to_vector(text).tolist()\n",
    "\n",
    "class GuidelineRetriever:\n",
    "    \"\"\"\n",
    "    A class to handle the storage and retrieval of medical guidelines using ChromaDB.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, persist_directory=\"./chroma_db\"):\n",
    "        \"\"\"\n",
    "        Initialize the retriever with a simple embedding approach.\n",
    "        \n",
    "        Args:\n",
    "            persist_directory: Directory to persist the vector database\n",
    "        \"\"\"\n",
    "        self.persist_directory = persist_directory\n",
    "        \n",
    "        # Use our simple embeddings implementation\n",
    "        self.embeddings = SimpleEmbeddings(dimension=100)\n",
    "        \n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(persist_directory, exist_ok=True)\n",
    "        \n",
    "        # Initialize the vector store\n",
    "        self.db = None\n",
    "    \n",
    "    def add_guidelines(self, guidelines_dir):\n",
    "        \"\"\"\n",
    "        Add medical guidelines from text files in a directory.\n",
    "        \n",
    "        Args:\n",
    "            guidelines_dir: Directory containing guideline text files\n",
    "        \"\"\"\n",
    "        # Load documents from the directory\n",
    "        loader = DirectoryLoader(guidelines_dir, glob=\"**/*.txt\", loader_cls=TextLoader)\n",
    "        documents = loader.load()\n",
    "        \n",
    "        # Split documents into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "        splits = text_splitter.split_documents(documents)\n",
    "        \n",
    "        # Create or update the vector store\n",
    "        self.db = Chroma.from_documents(\n",
    "            documents=splits,\n",
    "            embedding=self.embeddings,\n",
    "            persist_directory=self.persist_directory\n",
    "        )\n",
    "        \n",
    "        # Persist the database\n",
    "        self.db.persist()\n",
    "        \n",
    "        return len(splits)\n",
    "    \n",
    "    def add_guideline_text(self, text, metadata=None):\n",
    "        \"\"\"\n",
    "        Add a single guideline text to the vector store.\n",
    "        \n",
    "        Args:\n",
    "            text: The guideline text\n",
    "            metadata: Optional metadata for the document\n",
    "        \"\"\"\n",
    "        if metadata is None:\n",
    "            metadata = {}\n",
    "            \n",
    "        # Create a document\n",
    "        doc = Document(page_content=text, metadata=metadata)\n",
    "        \n",
    "        # Split the document\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "        splits = text_splitter.split_documents([doc])\n",
    "        \n",
    "        # Create or update the vector store\n",
    "        if self.db is None:\n",
    "            self.db = Chroma.from_documents(\n",
    "                documents=splits,\n",
    "                embedding=self.embeddings,\n",
    "                persist_directory=self.persist_directory\n",
    "            )\n",
    "        else:\n",
    "            self.db.add_documents(splits)\n",
    "        \n",
    "        # Persist the database\n",
    "        self.db.persist()\n",
    "        \n",
    "        return len(splits)\n",
    "    \n",
    "    def retrieve(self, query, top_k=3):\n",
    "        \"\"\"\n",
    "        Retrieve relevant guideline chunks based on a query.\n",
    "        \n",
    "        Args:\n",
    "            query: The search query\n",
    "            top_k: Number of results to return\n",
    "            \n",
    "        Returns:\n",
    "            List of retrieved documents\n",
    "        \"\"\"\n",
    "        if self.db is None:\n",
    "            return []\n",
    "            \n",
    "        results = self.db.similarity_search(query, k=top_k)\n",
    "        return results\n",
    "    \n",
    "    def load_if_exists(self):\n",
    "        \"\"\"\n",
    "        Load the vector store if it exists.\n",
    "        \n",
    "        Returns:\n",
    "            True if loaded successfully, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.db = Chroma(\n",
    "                persist_directory=self.persist_directory,\n",
    "                embedding_function=self.embeddings\n",
    "            )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading vector store: {e}\")\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Query Generator\n",
    "\n",
    "This component generates queries for retrieving relevant medical guidelines based on patient information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "class RecommendedQuery(BaseModel):\n",
    "    \"\"\"Represents a query to retrieve guideline sections relevant to the patient's conditions.\"\"\"\n",
    "    query: str\n",
    "    rationale: str = Field(..., description=\"Explanation of why this query is relevant to the patient.\")\n",
    "\n",
    "class QueryGenerator:\n",
    "    \"\"\"\n",
    "    A class to generate queries for retrieving relevant medical guidelines based on patient information.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the query generator.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def generate_queries(self, patient_info) -> List[RecommendedQuery]:\n",
    "        \"\"\"\n",
    "        Generate queries based on patient information.\n",
    "        \n",
    "        Args:\n",
    "            patient_info: PatientInfo object containing patient data\n",
    "            \n",
    "        Returns:\n",
    "            List of RecommendedQuery objects\n",
    "        \"\"\"\n",
    "        queries = []\n",
    "        \n",
    "        # Extract active conditions\n",
    "        active_conditions = [c for c in patient_info.conditions if c.clinical_status == \"active\"]\n",
    "        \n",
    "        # Generate queries for each active condition\n",
    "        for condition in active_conditions:\n",
    "            # Basic query for the condition\n",
    "            queries.append(\n",
    "                RecommendedQuery(\n",
    "                    query=f\"Treatment guidelines for {condition.display}\",\n",
    "                    rationale=f\"Patient has an active diagnosis of {condition.display}.\"\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Query for medication recommendations\n",
    "            queries.append(\n",
    "                RecommendedQuery(\n",
    "                    query=f\"Medication recommendations for {condition.display}\",\n",
    "                    rationale=f\"To evaluate if current medications align with guidelines for {condition.display}.\"\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Query for monitoring recommendations\n",
    "            queries.append(\n",
    "                RecommendedQuery(\n",
    "                    query=f\"Monitoring and follow-up for {condition.display}\",\n",
    "                    rationale=f\"To ensure appropriate monitoring for {condition.display}.\"\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # If patient has multiple conditions, add a query for comorbidities\n",
    "        if len(active_conditions) > 1:\n",
    "            condition_names = [c.display for c in active_conditions]\n",
    "            comorbidity_query = f\"Management of patients with {' and '.join(condition_names)}\"\n",
    "            queries.append(\n",
    "                RecommendedQuery(\n",
    "                    query=comorbidity_query,\n",
    "                    rationale=\"Patient has multiple conditions that may require coordinated management.\"\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Add age-specific queries if available\n",
    "        if patient_info.birth_date:\n",
    "            # Simple age calculation (not accounting for exact date)\n",
    "            try:\n",
    "                birth_year = int(patient_info.birth_date.split(\"-\")[0])\n",
    "                current_year = 2025  # Using current year as reference\n",
    "                age = current_year - birth_year\n",
    "                \n",
    "                if age >= 65:\n",
    "                    queries.append(\n",
    "                        RecommendedQuery(\n",
    "                            query=\"Elderly patient care guidelines\",\n",
    "                            rationale=f\"Patient is {age} years old and may require age-specific considerations.\"\n",
    "                        )\n",
    "                    )\n",
    "                elif age <= 18:\n",
    "                    queries.append(\n",
    "                        RecommendedQuery(\n",
    "                            query=\"Pediatric patient care guidelines\",\n",
    "                            rationale=f\"Patient is {age} years old and may require age-specific considerations.\"\n",
    "                        )\n",
    "                    )\n",
    "            except:\n",
    "                # If birth date parsing fails, skip age-specific queries\n",
    "                pass\n",
    "        \n",
    "        return queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 RAG Workflow\n",
    "\n",
    "This component ties everything together to process patient data, retrieve relevant guidelines, and generate a case summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List, Optional, Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "import json\n",
    "import os\n",
    "\n",
    "class CaseSummary(BaseModel):\n",
    "    \"\"\"Represents a patient case summary with recommendations.\"\"\"\n",
    "    patient_summary: str = Field(..., description=\"Summary of patient information\")\n",
    "    guideline_recommendations: str = Field(..., description=\"Recommendations based on clinical guidelines\")\n",
    "    care_gaps: str = Field(..., description=\"Identified gaps in care\")\n",
    "    next_steps: str = Field(..., description=\"Recommended next steps for the clinician\")\n",
    "\n",
    "class RAGWorkflow:\n",
    "    \"\"\"\n",
    "    A workflow that processes patient data, retrieves relevant guidelines,\n",
    "    and generates a case summary with recommendations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, guideline_retriever: GuidelineRetriever):\n",
    "        \"\"\"\n",
    "        Initialize the workflow.\n",
    "        \n",
    "        Args:\n",
    "            guideline_retriever: The retriever for medical guidelines\n",
    "        \"\"\"\n",
    "        self.guideline_retriever = guideline_retriever\n",
    "        self.query_generator = QueryGenerator()\n",
    "    \n",
    "    def process_patient(self, patient_info: PatientInfo) -> CaseSummary:\n",
    "        \"\"\"\n",
    "        Process patient information and generate a case summary.\n",
    "        \n",
    "        Args:\n",
    "            patient_info: PatientInfo object containing patient data\n",
    "            \n",
    "        Returns:\n",
    "            CaseSummary object\n",
    "        \"\"\"\n",
    "        # Generate queries based on patient information\n",
    "        recommended_queries = self.query_generator.generate_queries(patient_info)\n",
    "        \n",
    "        # Retrieve relevant guidelines for each query\n",
    "        all_guideline_docs = []\n",
    "        for query in recommended_queries:\n",
    "            guideline_docs = self.guideline_retriever.retrieve(query.query)\n",
    "            all_guideline_docs.extend(guideline_docs)\n",
    "        \n",
    "        # Deduplicate guidelines\n",
    "        unique_guideline_texts = set()\n",
    "        unique_guideline_docs = []\n",
    "        \n",
    "        for doc in all_guideline_docs:\n",
    "            if doc.page_content not in unique_guideline_texts:\n",
    "                unique_guideline_texts.add(doc.page_content)\n",
    "                unique_guideline_docs.append(doc)\n",
    "        \n",
    "        # Generate case summary using template-based approach\n",
    "        summary = self._generate_summary_with_template(patient_info, unique_guideline_docs, recommended_queries)\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def _generate_summary_with_template(self, patient_info: PatientInfo, guideline_docs: List, queries: List[RecommendedQuery]) -> CaseSummary:\n",
    "        \"\"\"\n",
    "        Generate a case summary using a template-based approach (no LLM).\n",
    "        \n",
    "        Args:\n",
    "            patient_info: PatientInfo object\n",
    "            guideline_docs: List of retrieved guideline documents\n",
    "            queries: List of recommended queries\n",
    "            \n",
    "        Returns:\n",
    "            CaseSummary object\n",
    "        \"\"\"\n",
    "        # Patient summary\n",
    "        patient_summary = f\"\"\"\n",
    "        Patient {patient_info.given_name} {patient_info.family_name} is a {patient_info.gender} \n",
    "        born on {patient_info.birth_date}. \n",
    "        \n",
    "        Active conditions: {', '.join([c.display for c in patient_info.conditions if c.clinical_status == 'active'])}\n",
    "        \n",
    "        Current medications: {', '.join([m.name for m in patient_info.current_medications])}\n",
    "        \n",
    "        Recent encounters: {', '.join([f\"{e.date}: {e.reason_display or e.type_display or 'Unknown'}\" for e in patient_info.recent_encounters[:3]])}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Guideline recommendations\n",
    "        guideline_recommendations = \"Based on retrieved guidelines:\\n\\n\"\n",
    "        \n",
    "        if guideline_docs:\n",
    "            for i, doc in enumerate(guideline_docs[:5]):  # Limit to 5 recommendations\n",
    "                guideline_recommendations += f\"- {doc.page_content[:200]}...\\n\\n\"\n",
    "        else:\n",
    "            guideline_recommendations += \"No specific guidelines were retrieved. Consider consulting standard care protocols.\\n\"\n",
    "        \n",
    "        # Care gaps (simplified without LLM)\n",
    "        care_gaps = \"\"\"\n",
    "        Potential care gaps to consider:\n",
    "        - Verify that current medications align with latest guideline recommendations\n",
    "        - Ensure appropriate monitoring and follow-up for all active conditions\n",
    "        - Check if preventive care measures are up-to-date\n",
    "        \"\"\"\n",
    "        \n",
    "        # Next steps\n",
    "        next_steps = \"\"\"\n",
    "        Recommended next steps:\n",
    "        1. Review the patient's current treatment plan against the guidelines\n",
    "        2. Consider adjustments to medications or monitoring if indicated\n",
    "        3. Schedule appropriate follow-up based on condition severity\n",
    "        4. Document any changes to the treatment plan\n",
    "        \"\"\"\n",
    "        \n",
    "        return CaseSummary(\n",
    "            patient_summary=patient_summary,\n",
    "            guideline_recommendations=guideline_recommendations,\n",
    "            care_gaps=care_gaps,\n",
    "            next_steps=next_steps\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Create Sample Patient Data\n",
    "\n",
    "Let's create a sample patient data file for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample patient data created at data/sample_patient.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "\n",
    "# Sample patient data in FHIR format\n",
    "patient_data = {\n",
    "    \"resourceType\": \"Bundle\",\n",
    "    \"type\": \"collection\",\n",
    "    \"entry\": [\n",
    "        {\n",
    "            \"resource\": {\n",
    "                \"resourceType\": \"Patient\",\n",
    "                \"id\": \"example-patient\",\n",
    "                \"name\": [\n",
    "                    {\n",
    "                        \"given\": [\"John\"],\n",
    "                        \"family\": \"Smith\"\n",
    "                    }\n",
    "                ],\n",
    "                \"birthDate\": \"1970-05-15\",\n",
    "                \"gender\": \"male\"\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"resource\": {\n",
    "                \"resourceType\": \"Condition\",\n",
    "                \"id\": \"condition-diabetes\",\n",
    "                \"subject\": {\n",
    "                    \"reference\": \"Patient/example-patient\"\n",
    "                },\n",
    "                \"code\": {\n",
    "                    \"coding\": [\n",
    "                        {\n",
    "                            \"system\": \"http://snomed.info/sct\",\n",
    "                            \"code\": \"73211009\",\n",
    "                            \"display\": \"Diabetes mellitus type 2\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                \"clinicalStatus\": {\n",
    "                    \"coding\": [\n",
    "                        {\n",
    "                            \"system\": \"http://terminology.hl7.org/CodeSystem/condition-clinical\",\n",
    "                            \"code\": \"active\",\n",
    "                            \"display\": \"Active\"\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"resource\": {\n",
    "                \"resourceType\": \"Condition\",\n",
    "                \"id\": \"condition-hypertension\",\n",
    "                \"subject\": {\n",
    "                    \"reference\": \"Patient/example-patient\"\n",
    "                },\n",
    "                \"code\": {\n",
    "                    \"coding\": [\n",
    "                        {\n",
    "                            \"system\": \"http://snomed.info/sct\",\n",
    "                            \"code\": \"38341003\",\n",
    "                            \"display\": \"Hypertension\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                \"clinicalStatus\": {\n",
    "                    \"coding\": [\n",
    "                        {\n",
    "                            \"system\": \"http://terminology.hl7.org/CodeSystem/condition-clinical\",\n",
    "                            \"code\": \"active\",\n",
    "                            \"display\": \"Active\"\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"resource\": {\n",
    "                \"resourceType\": \"MedicationRequest\",\n",
    "                \"id\": \"medication-metformin\",\n",
    "                \"subject\": {\n",
    "                    \"reference\": \"Patient/example-patient\"\n",
    "                },\n",
    "                \"medicationCodeableConcept\": {\n",
    "                    \"coding\": [\n",
    "                        {\n",
    "                            \"system\": \"http://www.nlm.nih.gov/research/umls/rxnorm\",\n",
    "                            \"code\": \"860975\",\n",
    "                            \"display\": \"Metformin 500 MG\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                \"authoredOn\": \"2023-01-15\",\n",
    "                \"status\": \"active\",\n",
    "                \"dosageInstruction\": [\n",
    "                    {\n",
    "                        \"text\": \"Take 500mg twice daily with meals\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"resource\": {\n",
    "                \"resourceType\": \"MedicationRequest\",\n",
    "                \"id\": \"medication-lisinopril\",\n",
    "                \"subject\": {\n",
    "                    \"reference\": \"Patient/example-patient\"\n",
    "                },\n",
    "                \"medicationCodeableConcept\": {\n",
    "                    \"coding\": [\n",
    "                        {\n",
    "                            \"system\": \"http://www.nlm.nih.gov/research/umls/rxnorm\",\n",
    "                            \"code\": \"314076\",\n",
    "                            \"display\": \"Lisinopril 10 MG\"\n",
    "                        }\n",
    "                    ]\n",
    "                },\n",
    "                \"authoredOn\": \"2023-02-10\",\n",
    "                \"status\": \"active\",\n",
    "                \"dosageInstruction\": [\n",
    "                    {\n",
    "                        \"text\": \"Take 10mg once daily\"\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"resource\": {\n",
    "                \"resourceType\": \"Encounter\",\n",
    "                \"id\": \"encounter-1\",\n",
    "                \"subject\": {\n",
    "                    \"reference\": \"Patient/example-patient\"\n",
    "                },\n",
    "                \"period\": {\n",
    "                    \"start\": \"2024-01-10\"\n",
    "                },\n",
    "                \"type\": [\n",
    "                    {\n",
    "                        \"coding\": [\n",
    "                            {\n",
    "                                \"system\": \"http://terminology.hl7.org/CodeSystem/encounter-type\",\n",
    "                                \"code\": \"AMB\",\n",
    "                                \"display\": \"Ambulatory\"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "                \"reasonCode\": [\n",
    "                    {\n",
    "                        \"coding\": [\n",
    "                            {\n",
    "                                \"system\": \"http://snomed.info/sct\",\n",
    "                                \"code\": \"73211009\",\n",
    "                                \"display\": \"Diabetes follow-up\"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            \"resource\": {\n",
    "                \"resourceType\": \"Encounter\",\n",
    "                \"id\": \"encounter-2\",\n",
    "                \"subject\": {\n",
    "                    \"reference\": \"Patient/example-patient\"\n",
    "                },\n",
    "                \"period\": {\n",
    "                    \"start\": \"2024-02-15\"\n",
    "                },\n",
    "                \"type\": [\n",
    "                    {\n",
    "                        \"coding\": [\n",
    "                            {\n",
    "                                \"system\": \"http://terminology.hl7.org/CodeSystem/encounter-type\",\n",
    "                                \"code\": \"AMB\",\n",
    "                                \"display\": \"Ambulatory\"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ],\n",
    "                \"reasonCode\": [\n",
    "                    {\n",
    "                        \"coding\": [\n",
    "                            {\n",
    "                                \"system\": \"http://snomed.info/sct\",\n",
    "                                \"code\": \"38341003\",\n",
    "                                \"display\": \"Hypertension follow-up\"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Save to file\n",
    "with open('data/sample_patient.json', 'w') as f:\n",
    "    json.dump(patient_data, f, indent=2)\n",
    "\n",
    "print(\"Sample patient data created at data/sample_patient.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create Sample Guidelines\n",
    "\n",
    "Let's create some sample medical guidelines for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample guidelines created in data/guidelines directory\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Create guidelines directory if it doesn't exist\n",
    "os.makedirs(\"data/guidelines\", exist_ok=True)\n",
    "\n",
    "# Sample diabetes guideline\n",
    "diabetes_guideline = \"\"\"\n",
    "# Diabetes Management Guidelines\n",
    "\n",
    "## Diagnosis\n",
    "Diabetes mellitus is diagnosed based on one of the following criteria:\n",
    "- Fasting plasma glucose  126 mg/dL (7.0 mmol/L)\n",
    "- 2-hour plasma glucose  200 mg/dL (11.1 mmol/L) during OGTT\n",
    "- A1C  6.5% (48 mmol/mol)\n",
    "- Random plasma glucose  200 mg/dL (11.1 mmol/L) in patients with symptoms of hyperglycemia\n",
    "\n",
    "## Treatment Goals\n",
    "- A1C < 7.0% for most adults\n",
    "- Blood pressure < 140/90 mmHg\n",
    "- LDL cholesterol < 100 mg/dL\n",
    "\n",
    "## Medication Recommendations\n",
    "First-line therapy: Metformin (unless contraindicated)\n",
    "Second-line options (based on patient factors):\n",
    "- GLP-1 receptor agonists\n",
    "- SGLT-2 inhibitors\n",
    "- DPP-4 inhibitors\n",
    "- Sulfonylureas\n",
    "- Thiazolidinediones\n",
    "- Insulin\n",
    "\n",
    "## Monitoring\n",
    "- A1C testing: Every 3 months until target is reached, then at least twice per year\n",
    "- Annual comprehensive foot examination\n",
    "- Annual dilated eye examination\n",
    "- Annual screening for albuminuria\n",
    "- Lipid profile and kidney function tests annually\n",
    "\"\"\"\n",
    "\n",
    "# Sample hypertension guideline\n",
    "hypertension_guideline = \"\"\"\n",
    "# Hypertension Management Guidelines\n",
    "\n",
    "## Diagnosis\n",
    "Hypertension is defined as:\n",
    "- Systolic BP  130 mmHg or\n",
    "- Diastolic BP  80 mmHg\n",
    "\n",
    "## Classification\n",
    "- Normal: < 120/80 mmHg\n",
    "- Elevated: 120-129/< 80 mmHg\n",
    "- Stage 1: 130-139/80-89 mmHg\n",
    "- Stage 2:  140/90 mmHg\n",
    "\n",
    "## Treatment Goals\n",
    "- General population: < 130/80 mmHg\n",
    "- Older adults ( 65 years): Target based on clinical judgment and patient preference\n",
    "\n",
    "## Medication Recommendations\n",
    "First-line agents:\n",
    "- Thiazide diuretics\n",
    "- ACE inhibitors\n",
    "- ARBs\n",
    "- Calcium channel blockers\n",
    "\n",
    "## Monitoring\n",
    "- Home BP monitoring is recommended\n",
    "- Follow-up every 3-6 months for stable patients\n",
    "- Annual screening for other cardiovascular risk factors\n",
    "\"\"\"\n",
    "\n",
    "# Save the guidelines to files\n",
    "with open('data/guidelines/diabetes.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(diabetes_guideline)\n",
    "\n",
    "with open('data/guidelines/hypertension.txt', 'w', encoding='utf-8') as f:\n",
    "    f.write(hypertension_guideline)\n",
    "\n",
    "print(\"Sample guidelines created in data/guidelines directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize the RAG Application\n",
    "\n",
    "Now let's initialize the RAG application components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 2 chunks to the vector database.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aryan\\AppData\\Local\\Temp\\ipykernel_16948\\3908504600.py:110: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n",
      "  self.db.persist()\n"
     ]
    }
   ],
   "source": [
    "# Create a persistent directory for the vector store\n",
    "os.makedirs(\"./chroma_db\", exist_ok=True)\n",
    "\n",
    "# Initialize the guideline retriever\n",
    "guideline_retriever = GuidelineRetriever(persist_directory=\"./chroma_db\")\n",
    "\n",
    "# Add the guidelines to the vector store\n",
    "num_chunks = guideline_retriever.add_guidelines(\"data/guidelines\")\n",
    "print(f\"Added {num_chunks} chunks to the vector database.\")\n",
    "\n",
    "# Initialize the RAG workflow\n",
    "workflow = RAGWorkflow(guideline_retriever=guideline_retriever)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Process Patient Data\n",
    "\n",
    "Let's process the sample patient data and generate a case summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Patient: John Smith\n",
      "Birth Date: 1970-05-15\n",
      "Gender: male\n",
      "\n",
      "Conditions:\n",
      "- Diabetes mellitus type 2 (Status: active)\n",
      "- Hypertension (Status: active)\n",
      "\n",
      "Current Medications:\n",
      "- Metformin 500 MG\n",
      "  Instructions: Take 500mg twice daily with meals\n",
      "- Lisinopril 10 MG\n",
      "  Instructions: Take 10mg once daily\n",
      "\n",
      "Recent Encounters:\n",
      "- 2024-02-15: Hypertension follow-up\n",
      "- 2024-01-10: Diabetes follow-up\n"
     ]
    }
   ],
   "source": [
    "# Parse the patient data\n",
    "patient_info = parse_synthea_patient(\"data/sample_patient.json\")\n",
    "\n",
    "# Display patient information\n",
    "print(f\"Patient: {patient_info.given_name} {patient_info.family_name}\")\n",
    "print(f\"Birth Date: {patient_info.birth_date}\")\n",
    "print(f\"Gender: {patient_info.gender}\")\n",
    "print(\"\\nConditions:\")\n",
    "for condition in patient_info.conditions:\n",
    "    print(f\"- {condition.display} (Status: {condition.clinical_status})\")\n",
    "print(\"\\nCurrent Medications:\")\n",
    "for med in patient_info.current_medications:\n",
    "    print(f\"- {med.name}\")\n",
    "    if med.instructions:\n",
    "        print(f\"  Instructions: {med.instructions}\")\n",
    "print(\"\\nRecent Encounters:\")\n",
    "for encounter in patient_info.recent_encounters[:3]:  # Show only 3 most recent\n",
    "    reason = encounter.reason_display or encounter.type_display or \"Unknown\"\n",
    "    print(f\"- {encounter.date}: {reason}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generate Queries\n",
    "\n",
    "Let's generate queries based on the patient information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommended Queries:\n",
      "\n",
      "Query 1: Treatment guidelines for Diabetes mellitus type 2\n",
      "Rationale: Patient has an active diagnosis of Diabetes mellitus type 2.\n",
      "\n",
      "Query 2: Medication recommendations for Diabetes mellitus type 2\n",
      "Rationale: To evaluate if current medications align with guidelines for Diabetes mellitus type 2.\n",
      "\n",
      "Query 3: Monitoring and follow-up for Diabetes mellitus type 2\n",
      "Rationale: To ensure appropriate monitoring for Diabetes mellitus type 2.\n",
      "\n",
      "Query 4: Treatment guidelines for Hypertension\n",
      "Rationale: Patient has an active diagnosis of Hypertension.\n",
      "\n",
      "Query 5: Medication recommendations for Hypertension\n",
      "Rationale: To evaluate if current medications align with guidelines for Hypertension.\n",
      "\n",
      "Query 6: Monitoring and follow-up for Hypertension\n",
      "Rationale: To ensure appropriate monitoring for Hypertension.\n",
      "\n",
      "Query 7: Management of patients with Diabetes mellitus type 2 and Hypertension\n",
      "Rationale: Patient has multiple conditions that may require coordinated management.\n"
     ]
    }
   ],
   "source": [
    "# Generate queries\n",
    "query_generator = QueryGenerator()\n",
    "recommended_queries = query_generator.generate_queries(patient_info)\n",
    "\n",
    "# Display the recommended queries\n",
    "print(\"Recommended Queries:\")\n",
    "for i, query in enumerate(recommended_queries):\n",
    "    print(f\"\\nQuery {i+1}: {query.query}\")\n",
    "    print(f\"Rationale: {query.rationale}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Generate Case Summary\n",
    "\n",
    "Now let's generate a case summary for the patient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PATIENT SUMMARY\n",
      "==============\n",
      "\n",
      "\n",
      "        Patient John Smith is a male \n",
      "        born on 1970-05-15. \n",
      "        \n",
      "        Active conditions: Diabetes mellitus type 2, Hypertension\n",
      "        \n",
      "        Current medications: Metformin 500 MG, Lisinopril 10 MG\n",
      "        \n",
      "        Recent encounters: 2024-02-15: Hypertension follow-up, 2024-01-10: Diabetes follow-up\n",
      "        \n",
      "\n",
      "GUIDELINE RECOMMENDATIONS\n",
      "========================\n",
      "\n",
      "Based on retrieved guidelines:\n",
      "\n",
      "- # Hypertension Management Guidelines\n",
      "\n",
      "## Diagnosis\n",
      "Hypertension is defined as:\n",
      "- Systolic BP  130 mmHg or\n",
      "- Diastolic BP  80 mmHg\n",
      "\n",
      "## Classification\n",
      "- Normal: < 120/80 mmHg\n",
      "- Elevated: 120-129/<...\n",
      "\n",
      "- # Diabetes Management Guidelines\n",
      "\n",
      "## Diagnosis\n",
      "Diabetes mellitus is diagnosed based on one of the following criteria:\n",
      "- Fasting plasma glucose  126 mg/dL (7.0 mmol/L)\n",
      "- 2-hour plasma glucose  20...\n",
      "\n",
      "\n",
      "\n",
      "CARE GAPS\n",
      "=========\n",
      "\n",
      "\n",
      "        Potential care gaps to consider:\n",
      "        - Verify that current medications align with latest guideline recommendations\n",
      "        - Ensure appropriate monitoring and follow-up for all active conditions\n",
      "        - Check if preventive care measures are up-to-date\n",
      "        \n",
      "\n",
      "NEXT STEPS\n",
      "==========\n",
      "\n",
      "\n",
      "        Recommended next steps:\n",
      "        1. Review the patient's current treatment plan against the guidelines\n",
      "        2. Consider adjustments to medications or monitoring if indicated\n",
      "        3. Schedule appropriate follow-up based on condition severity\n",
      "        4. Document any changes to the treatment plan\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "# Process the patient data through the workflow\n",
    "case_summary = workflow.process_patient(patient_info)\n",
    "\n",
    "# Display the case summary\n",
    "print(\"PATIENT SUMMARY\")\n",
    "print(\"==============\\n\")\n",
    "print(case_summary.patient_summary)\n",
    "\n",
    "print(\"\\nGUIDELINE RECOMMENDATIONS\")\n",
    "print(\"========================\\n\")\n",
    "print(case_summary.guideline_recommendations)\n",
    "\n",
    "print(\"\\nCARE GAPS\")\n",
    "print(\"=========\\n\")\n",
    "print(case_summary.care_gaps)\n",
    "\n",
    "print(\"\\nNEXT STEPS\")\n",
    "print(\"==========\\n\")\n",
    "print(case_summary.next_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Interactive Interface\n",
    "\n",
    "Let's create an interactive interface for the RAG application using IPython widgets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Aryan\\AppData\\Local\\Temp\\ipykernel_16948\\3089562711.py:239: LangChainDeprecationWarning: The class `Chroma` was deprecated in LangChain 0.2.9 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-chroma package and should be used instead. To use it run `pip install -U :class:`~langchain-chroma` and import as `from :class:`~langchain_chroma import Chroma``.\n",
      "  self.db = Chroma(\n",
      "2025-03-13 09:12:37.369 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.369 WARNING streamlit.runtime.state.session_state_proxy: Session state does not function when running a script without `streamlit run`\n",
      "2025-03-13 09:12:37.369 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.369 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.369 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.376 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.377 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.377 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.378 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.379 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.380 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.380 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.380 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.380 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.384 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.386 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.386 WARNING streamlit.runtime.scriptrunner_utils.script_run_context: Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.902 \n",
      "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
      "  command:\n",
      "\n",
      "    streamlit run C:\\Users\\Aryan\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\ipykernel_launcher.py [ARGUMENTS]\n",
      "2025-03-13 09:12:37.902 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.902 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.902 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.909 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.910 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.910 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.910 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.910 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.910 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.910 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.910 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.918 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.918 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.918 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.918 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.918 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.918 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.918 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.918 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.918 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.918 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.926 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.927 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.927 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.927 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.927 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.927 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.936 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.936 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.936 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.936 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.944 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.944 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.952 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.952 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.952 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.952 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.952 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.960 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.960 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.960 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.968 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.969 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.969 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.969 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.969 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.969 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.969 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.969 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.976 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.977 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.977 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.977 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.986 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.986 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.994 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.994 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.994 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.994 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:37.994 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:38.001 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:38.002 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:38.002 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:38.002 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:38.002 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n",
      "2025-03-13 09:12:38.002 Thread 'MainThread': missing ScriptRunContext! This warning can be ignored when running in bare mode.\n"
     ]
    }
   ],
   "source": [
    "import streamlit as st\n",
    "import json\n",
    "import os\n",
    "import tempfile\n",
    "import numpy as np\n",
    "from typing import List, Optional, Dict, Any\n",
    "from pydantic import BaseModel, Field\n",
    "import pypdf\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.document_loaders import TextLoader, DirectoryLoader\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(\"data\", exist_ok=True)\n",
    "os.makedirs(\"data/guidelines\", exist_ok=True)\n",
    "os.makedirs(\"chroma_db\", exist_ok=True)\n",
    "\n",
    "# Define Pydantic models\n",
    "class ConditionInfo(BaseModel):\n",
    "    code: str\n",
    "    display: str\n",
    "    clinical_status: str\n",
    "\n",
    "class EncounterInfo(BaseModel):\n",
    "    date: str = Field(..., description=\"Date of the encounter.\")\n",
    "    reason_display: Optional[str] = Field(None, description=\"Reason for the encounter.\")\n",
    "    type_display: Optional[str] = Field(None, description=\"Type or class of the encounter.\")\n",
    "\n",
    "class MedicationInfo(BaseModel):\n",
    "    name: str = Field(..., description=\"Name of the medication.\")\n",
    "    start_date: Optional[str] = Field(None, description=\"When the medication was prescribed.\")\n",
    "    instructions: Optional[str] = Field(None, description=\"Dosage instructions.\")\n",
    "\n",
    "class PatientInfo(BaseModel):\n",
    "    given_name: str\n",
    "    family_name: str\n",
    "    birth_date: str\n",
    "    gender: str\n",
    "    conditions: List[ConditionInfo] = Field(default_factory=list)\n",
    "    recent_encounters: List[EncounterInfo] = Field(default_factory=list, description=\"A few recent encounters.\")\n",
    "    current_medications: List[MedicationInfo] = Field(default_factory=list, description=\"Current active medications.\")\n",
    "\n",
    "    @property\n",
    "    def demographic_str(self) -> str:\n",
    "        \"\"\"Get demographics string.\"\"\"\n",
    "        return f\"\"\"\\\n",
    "Given name: {self.given_name}\n",
    "Family name: {self.family_name}\n",
    "Birth date: {self.birth_date}\n",
    "Gender: {self.gender}\"\"\"\n",
    "\n",
    "class RecommendedQuery(BaseModel):\n",
    "    \"\"\"Represents a query to retrieve guideline sections relevant to the patient's conditions.\"\"\"\n",
    "    query: str\n",
    "    rationale: str = Field(..., description=\"Explanation of why this query is relevant to the patient.\")\n",
    "\n",
    "class CaseSummary(BaseModel):\n",
    "    \"\"\"Represents a patient case summary with recommendations.\"\"\"\n",
    "    patient_summary: str = Field(..., description=\"Summary of patient information\")\n",
    "    guideline_recommendations: str = Field(..., description=\"Recommendations based on clinical guidelines\")\n",
    "    care_gaps: str = Field(..., description=\"Identified gaps in care\")\n",
    "    next_steps: str = Field(..., description=\"Recommended next steps for the clinician\")\n",
    "\n",
    "# Define SimpleEmbeddings class\n",
    "class SimpleEmbeddings:\n",
    "    \"\"\"\n",
    "    A simple embedding class that uses TF-IDF like approach for text embeddings.\n",
    "    This is a lightweight alternative that doesn't require external models.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dimension=100):\n",
    "        \"\"\"Initialize with a fixed embedding dimension.\"\"\"\n",
    "        self.dimension = dimension\n",
    "        self.vocabulary = {}\n",
    "        self.vocab_size = 0\n",
    "        \n",
    "    def _preprocess_text(self, text):\n",
    "        \"\"\"Simple text preprocessing.\"\"\"\n",
    "        # Convert to lowercase and split by whitespace\n",
    "        return text.lower().split()\n",
    "        \n",
    "    def _update_vocabulary(self, tokens):\n",
    "        \"\"\"Update vocabulary with new tokens.\"\"\"\n",
    "        for token in tokens:\n",
    "            if token not in self.vocabulary:\n",
    "                self.vocabulary[token] = self.vocab_size\n",
    "                self.vocab_size += 1\n",
    "    \n",
    "    def _text_to_vector(self, text):\n",
    "        \"\"\"Convert text to a fixed-dimension vector.\"\"\"\n",
    "        tokens = self._preprocess_text(text)\n",
    "        self._update_vocabulary(tokens)\n",
    "        \n",
    "        # Create a simple frequency vector\n",
    "        vec = np.zeros(self.dimension)\n",
    "        for token in tokens:\n",
    "            if token in self.vocabulary:\n",
    "                # Use modulo to ensure we stay within dimension\n",
    "                idx = self.vocabulary[token] % self.dimension\n",
    "                vec[idx] += 1\n",
    "        \n",
    "        # Normalize the vector\n",
    "        norm = np.linalg.norm(vec)\n",
    "        if norm > 0:\n",
    "            vec = vec / norm\n",
    "        return vec\n",
    "    \n",
    "    def embed_documents(self, texts: List[str]) -> List[List[float]]:\n",
    "        \"\"\"Embed a list of documents.\"\"\"\n",
    "        return [self._text_to_vector(text).tolist() for text in texts]\n",
    "    \n",
    "    def embed_query(self, text: str) -> List[float]:\n",
    "        \"\"\"Embed a query.\"\"\"\n",
    "        return self._text_to_vector(text).tolist()\n",
    "\n",
    "# Define GuidelineRetriever class\n",
    "class GuidelineRetriever:\n",
    "    \"\"\"\n",
    "    A class to handle the storage and retrieval of medical guidelines using ChromaDB.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, persist_directory=\"./chroma_db\"):\n",
    "        \"\"\"\n",
    "        Initialize the retriever with a simple embedding approach.\n",
    "        \n",
    "        Args:\n",
    "            persist_directory: Directory to persist the vector database\n",
    "        \"\"\"\n",
    "        self.persist_directory = persist_directory\n",
    "        \n",
    "        # Use our simple embeddings implementation\n",
    "        self.embeddings = SimpleEmbeddings(dimension=100)\n",
    "        \n",
    "        # Create the directory if it doesn't exist\n",
    "        os.makedirs(persist_directory, exist_ok=True)\n",
    "        \n",
    "        # Initialize the vector store\n",
    "        self.db = None\n",
    "        self.load_if_exists()\n",
    "    \n",
    "    def add_guidelines(self, guidelines_dir):\n",
    "        \"\"\"\n",
    "        Add medical guidelines from text files in a directory.\n",
    "        \n",
    "        Args:\n",
    "            guidelines_dir: Directory containing guideline text files\n",
    "        \"\"\"\n",
    "        # Load documents from the directory\n",
    "        loader = DirectoryLoader(guidelines_dir, glob=\"**/*.txt\", loader_cls=TextLoader)\n",
    "        documents = loader.load()\n",
    "        \n",
    "        if not documents:\n",
    "            return 0\n",
    "            \n",
    "        # Split documents into chunks\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "        splits = text_splitter.split_documents(documents)\n",
    "        \n",
    "        # Create or update the vector store\n",
    "        if self.db is None:\n",
    "            self.db = Chroma.from_documents(\n",
    "                documents=splits,\n",
    "                embedding=self.embeddings,\n",
    "                persist_directory=self.persist_directory\n",
    "            )\n",
    "        else:\n",
    "            self.db.add_documents(splits)\n",
    "        \n",
    "        # Persist the database\n",
    "        self.db.persist()\n",
    "        \n",
    "        return len(splits)\n",
    "    \n",
    "    def add_guideline_text(self, text, metadata=None):\n",
    "        \"\"\"\n",
    "        Add a single guideline text to the vector store.\n",
    "        \n",
    "        Args:\n",
    "            text: The guideline text\n",
    "            metadata: Optional metadata for the document\n",
    "        \"\"\"\n",
    "        if metadata is None:\n",
    "            metadata = {}\n",
    "            \n",
    "        # Create a document\n",
    "        doc = Document(page_content=text, metadata=metadata)\n",
    "        \n",
    "        # Split the document\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=1000,\n",
    "            chunk_overlap=200\n",
    "        )\n",
    "        splits = text_splitter.split_documents([doc])\n",
    "        \n",
    "        # Create or update the vector store\n",
    "        if self.db is None:\n",
    "            self.db = Chroma.from_documents(\n",
    "                documents=splits,\n",
    "                embedding=self.embeddings,\n",
    "                persist_directory=self.persist_directory\n",
    "            )\n",
    "        else:\n",
    "            self.db.add_documents(splits)\n",
    "        \n",
    "        # Persist the database\n",
    "        self.db.persist()\n",
    "        \n",
    "        return len(splits)\n",
    "    \n",
    "    def retrieve(self, query, top_k=3):\n",
    "        \"\"\"\n",
    "        Retrieve relevant guideline chunks based on a query.\n",
    "        \n",
    "        Args:\n",
    "            query: The search query\n",
    "            top_k: Number of results to return\n",
    "            \n",
    "        Returns:\n",
    "            List of retrieved documents\n",
    "        \"\"\"\n",
    "        if self.db is None:\n",
    "            return []\n",
    "            \n",
    "        results = self.db.similarity_search(query, k=top_k)\n",
    "        return results\n",
    "    \n",
    "    def load_if_exists(self):\n",
    "        \"\"\"\n",
    "        Load the vector store if it exists.\n",
    "        \n",
    "        Returns:\n",
    "            True if loaded successfully, False otherwise\n",
    "        \"\"\"\n",
    "        try:\n",
    "            self.db = Chroma(\n",
    "                persist_directory=self.persist_directory,\n",
    "                embedding_function=self.embeddings\n",
    "            )\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading vector store: {e}\")\n",
    "            return False\n",
    "\n",
    "# Define QueryGenerator class\n",
    "class QueryGenerator:\n",
    "    \"\"\"\n",
    "    A class to generate queries for retrieving relevant medical guidelines based on patient information.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        \"\"\"Initialize the query generator.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def generate_queries(self, patient_info) -> List[RecommendedQuery]:\n",
    "        \"\"\"\n",
    "        Generate queries based on patient information.\n",
    "        \n",
    "        Args:\n",
    "            patient_info: PatientInfo object containing patient data\n",
    "            \n",
    "        Returns:\n",
    "            List of RecommendedQuery objects\n",
    "        \"\"\"\n",
    "        queries = []\n",
    "        \n",
    "        # Extract active conditions\n",
    "        active_conditions = [c for c in patient_info.conditions if c.clinical_status == \"active\"]\n",
    "        \n",
    "        # Generate queries for each active condition\n",
    "        for condition in active_conditions:\n",
    "            # Basic query for the condition\n",
    "            queries.append(\n",
    "                RecommendedQuery(\n",
    "                    query=f\"Treatment guidelines for {condition.display}\",\n",
    "                    rationale=f\"Patient has an active diagnosis of {condition.display}.\"\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Query for medication recommendations\n",
    "            queries.append(\n",
    "                RecommendedQuery(\n",
    "                    query=f\"Medication recommendations for {condition.display}\",\n",
    "                    rationale=f\"To evaluate if current medications align with guidelines for {condition.display}.\"\n",
    "                )\n",
    "            )\n",
    "            \n",
    "            # Query for monitoring recommendations\n",
    "            queries.append(\n",
    "                RecommendedQuery(\n",
    "                    query=f\"Monitoring and follow-up for {condition.display}\",\n",
    "                    rationale=f\"To ensure appropriate monitoring for {condition.display}.\"\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # If patient has multiple conditions, add a query for comorbidities\n",
    "        if len(active_conditions) > 1:\n",
    "            condition_names = [c.display for c in active_conditions]\n",
    "            comorbidity_query = f\"Management of patients with {' and '.join(condition_names)}\"\n",
    "            queries.append(\n",
    "                RecommendedQuery(\n",
    "                    query=comorbidity_query,\n",
    "                    rationale=\"Patient has multiple conditions that may require coordinated management.\"\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        # Add age-specific queries if available\n",
    "        if patient_info.birth_date:\n",
    "            # Simple age calculation (not accounting for exact date)\n",
    "            try:\n",
    "                birth_year = int(patient_info.birth_date.split(\"-\")[0])\n",
    "                current_year = 2025  # Using current year as reference\n",
    "                age = current_year - birth_year\n",
    "                \n",
    "                if age >= 65:\n",
    "                    queries.append(\n",
    "                        RecommendedQuery(\n",
    "                            query=\"Elderly patient care guidelines\",\n",
    "                            rationale=f\"Patient is {age} years old and may require age-specific considerations.\"\n",
    "                        )\n",
    "                    )\n",
    "                elif age <= 18:\n",
    "                    queries.append(\n",
    "                        RecommendedQuery(\n",
    "                            query=\"Pediatric patient care guidelines\",\n",
    "                            rationale=f\"Patient is {age} years old and may require age-specific considerations.\"\n",
    "                        )\n",
    "                    )\n",
    "            except:\n",
    "                # If birth date parsing fails, skip age-specific queries\n",
    "                pass\n",
    "        \n",
    "        return queries\n",
    "\n",
    "# Define RAGWorkflow class\n",
    "class RAGWorkflow:\n",
    "    \"\"\"\n",
    "    A workflow that processes patient data, retrieves relevant guidelines,\n",
    "    and generates a case summary with recommendations.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, guideline_retriever: GuidelineRetriever):\n",
    "        \"\"\"\n",
    "        Initialize the workflow.\n",
    "        \n",
    "        Args:\n",
    "            guideline_retriever: The retriever for medical guidelines\n",
    "        \"\"\"\n",
    "        self.guideline_retriever = guideline_retriever\n",
    "        self.query_generator = QueryGenerator()\n",
    "    \n",
    "    def process_patient(self, patient_info: PatientInfo) -> CaseSummary:\n",
    "        \"\"\"\n",
    "        Process patient information and generate a case summary.\n",
    "        \n",
    "        Args:\n",
    "            patient_info: PatientInfo object containing patient data\n",
    "            \n",
    "        Returns:\n",
    "            CaseSummary object\n",
    "        \"\"\"\n",
    "        # Generate queries based on patient information\n",
    "        recommended_queries = self.query_generator.generate_queries(patient_info)\n",
    "        \n",
    "        # Retrieve relevant guidelines for each query\n",
    "        all_guideline_docs = []\n",
    "        for query in recommended_queries:\n",
    "            guideline_docs = self.guideline_retriever.retrieve(query.query)\n",
    "            all_guideline_docs.extend(guideline_docs)\n",
    "        \n",
    "        # Deduplicate guidelines\n",
    "        unique_guideline_texts = set()\n",
    "        unique_guideline_docs = []\n",
    "        \n",
    "        for doc in all_guideline_docs:\n",
    "            if doc.page_content not in unique_guideline_texts:\n",
    "                unique_guideline_texts.add(doc.page_content)\n",
    "                unique_guideline_docs.append(doc)\n",
    "        \n",
    "        # Generate case summary using template-based approach\n",
    "        summary = self._generate_summary_with_template(patient_info, unique_guideline_docs, recommended_queries)\n",
    "        \n",
    "        return summary\n",
    "    \n",
    "    def _generate_summary_with_template(self, patient_info: PatientInfo, guideline_docs: List, queries: List[RecommendedQuery]) -> CaseSummary:\n",
    "        \"\"\"\n",
    "        Generate a case summary using a template-based approach (no LLM).\n",
    "        \n",
    "        Args:\n",
    "            patient_info: PatientInfo object\n",
    "            guideline_docs: List of retrieved guideline documents\n",
    "            queries: List of recommended queries\n",
    "            \n",
    "        Returns:\n",
    "            CaseSummary object\n",
    "        \"\"\"\n",
    "        # Patient summary\n",
    "        patient_summary = f\"\"\"\n",
    "        Patient {patient_info.given_name} {patient_info.family_name} is a {patient_info.gender} \n",
    "        born on {patient_info.birth_date}. \n",
    "        \n",
    "        Active conditions: {', '.join([c.display for c in patient_info.conditions if c.clinical_status == 'active'])}\n",
    "        \n",
    "        Current medications: {', '.join([m.name for m in patient_info.current_medications])}\n",
    "        \n",
    "        Recent encounters: {', '.join([f\"{e.date}: {e.reason_display or e.type_display or 'Unknown'}\" for e in patient_info.recent_encounters[:3]])}\n",
    "        \"\"\"\n",
    "        \n",
    "        # Guideline recommendations\n",
    "        guideline_recommendations = \"Based on retrieved guidelines:\\n\\n\"\n",
    "        \n",
    "        if guideline_docs:\n",
    "            for i, doc in enumerate(guideline_docs[:5]):  # Limit to 5 recommendations\n",
    "                guideline_recommendations += f\"- {doc.page_content[:200]}...\\n\\n\"\n",
    "        else:\n",
    "            guideline_recommendations += \"No specific guidelines were retrieved. Consider consulting standard care protocols.\\n\"\n",
    "        \n",
    "        # Care gaps (simplified without LLM)\n",
    "        care_gaps = \"\"\"\n",
    "        Potential care gaps to consider:\n",
    "        - Verify that current medications align with latest guideline recommendations\n",
    "        - Ensure appropriate monitoring and follow-up for all active conditions\n",
    "        - Check if preventive care measures are up-to-date\n",
    "        \"\"\"\n",
    "        \n",
    "        # Next steps\n",
    "        next_steps = \"\"\"\n",
    "        Recommended next steps:\n",
    "        1. Review the patient's current treatment plan against the guidelines\n",
    "        2. Consider adjustments to medications or monitoring if indicated\n",
    "        3. Schedule appropriate follow-up based on condition severity\n",
    "        4. Document any changes to the treatment plan\n",
    "        \"\"\"\n",
    "        \n",
    "        return CaseSummary(\n",
    "            patient_summary=patient_summary,\n",
    "            guideline_recommendations=guideline_recommendations,\n",
    "            care_gaps=care_gaps,\n",
    "            next_steps=next_steps\n",
    "        )\n",
    "\n",
    "# Define functions for patient data parsing\n",
    "def parse_synthea_patient(file_path: str, filter_active: bool = True) -> PatientInfo:\n",
    "    \"\"\"\n",
    "    Parse a Synthea-generated FHIR Bundle to extract patient information.\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to the JSON file containing the FHIR Bundle\n",
    "        filter_active: Whether to filter for only active conditions\n",
    "        \n",
    "    Returns:\n",
    "        PatientInfo object containing extracted patient data\n",
    "    \"\"\"\n",
    "    # Load the Synthea-generated FHIR Bundle\n",
    "    with open(file_path, \"r\") as f:\n",
    "        bundle = json.load(f)\n",
    "\n",
    "    patient_resource = None\n",
    "    conditions = []\n",
    "    encounters = []\n",
    "    medication_requests = []\n",
    "\n",
    "    for entry in bundle.get(\"entry\", []):\n",
    "        resource = entry.get(\"resource\", {})\n",
    "        resource_type = resource.get(\"resourceType\")\n",
    "\n",
    "        if resource_type == \"Patient\":\n",
    "            patient_resource = resource\n",
    "        elif resource_type == \"Condition\":\n",
    "            conditions.append(resource)\n",
    "        elif resource_type == \"Encounter\":\n",
    "            encounters.append(resource)\n",
    "        elif resource_type == \"MedicationRequest\":\n",
    "            medication_requests.append(resource)\n",
    "\n",
    "    if not patient_resource:\n",
    "        raise ValueError(\"No Patient resource found in the provided file.\")\n",
    "\n",
    "    # Extract patient demographics\n",
    "    name_entry = patient_resource.get(\"name\", [{}])[0]\n",
    "    given_name = name_entry.get(\"given\", [\"\"])[0]\n",
    "    family_name = name_entry.get(\"family\", \"\")\n",
    "    birth_date = patient_resource.get(\"birthDate\", \"\")\n",
    "    gender = patient_resource.get(\"gender\", \"\")\n",
    "\n",
    "    # Create PatientInfo object\n",
    "    patient_info = PatientInfo(\n",
    "        given_name=given_name,\n",
    "        family_name=family_name,\n",
    "        birth_date=birth_date,\n",
    "        gender=gender\n",
    "    )\n",
    "\n",
    "    # Extract conditions\n",
    "    for condition in conditions:\n",
    "        clinical_status = condition.get(\"clinicalStatus\", {}).get(\"coding\", [{}])[0].get(\"code\", \"\")\n",
    "        \n",
    "        # Skip if not active and filter_active is True\n",
    "        if filter_active and clinical_status != \"active\":\n",
    "            continue\n",
    "            \n",
    "        code_entry = condition.get(\"code\", {}).get(\"coding\", [{}])[0]\n",
    "        code = code_entry.get(\"code\", \"\")\n",
    "        display = code_entry.get(\"display\", \"\")\n",
    "        \n",
    "        patient_info.conditions.append(\n",
    "            ConditionInfo(\n",
    "                code=code,\n",
    "                display=display,\n",
    "                clinical_status=clinical_status\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Extract recent encounters (sort by date, most recent first)\n",
    "    sorted_encounters = sorted(\n",
    "        encounters,\n",
    "        key=lambda e: e.get(\"period\", {}).get(\"start\", \"\"),\n",
    "        reverse=True\n",
    "    )\n",
    "    \n",
    "    for encounter in sorted_encounters[:5]:  # Get 5 most recent encounters\n",
    "        period = encounter.get(\"period\", {})\n",
    "        date = period.get(\"start\", \"\")\n",
    "        \n",
    "        reason_display = \"\"\n",
    "        if encounter.get(\"reasonCode\"):\n",
    "            reason_display = encounter.get(\"reasonCode\", [{}])[0].get(\"coding\", [{}])[0].get(\"display\", \"\")\n",
    "        \n",
    "        type_display = \"\"\n",
    "        if encounter.get(\"type\"):\n",
    "            type_display = encounter.get(\"type\", [{}])[0].get(\"coding\", [{}])[0].get(\"display\", \"\")\n",
    "        \n",
    "        patient_info.recent_encounters.append(\n",
    "            EncounterInfo(\n",
    "                date=date,\n",
    "                reason_display=reason_display,\n",
    "                type_display=type_display\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # Extract current medications\n",
    "    for med_request in medication_requests:\n",
    "        status = med_request.get(\"status\", \"\")\n",
    "        \n",
    "        # Skip if not active and filter_active is True\n",
    "        if filter_active and status != \"active\":\n",
    "            continue\n",
    "            \n",
    "        med_code_entry = med_request.get(\"medicationCodeableConcept\", {}).get(\"coding\", [{}])[0]\n",
    "        med_name = med_code_entry.get(\"display\", \"\")\n",
    "        \n",
    "        dosage_instruction = med_request.get(\"dosageInstruction\", [{}])[0]\n",
    "        text_instruction = dosage_instruction.get(\"text\", \"\")\n",
    "        \n",
    "        start_date = \"\"\n",
    "        if med_request.get(\"authoredOn\"):\n",
    "            start_date = med_request.get(\"authoredOn\", \"\")\n",
    "        \n",
    "        patient_info.current_medications.append(\n",
    "            MedicationInfo(\n",
    "                name=med_name,\n",
    "                start_date=start_date,\n",
    "                instructions=text_instruction\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return patient_info\n",
    "\n",
    "# Define functions for PDF processing\n",
    "def extract_text_from_pdf(pdf_file):\n",
    "    \"\"\"\n",
    "    Extract text from a PDF file.\n",
    "    \n",
    "    Args:\n",
    "        pdf_file: Uploaded PDF file\n",
    "        \n",
    "    Returns:\n",
    "        Extracted text as a string\n",
    "    \"\"\"\n",
    "    text = \"\"\n",
    "    try:\n",
    "        # Create a temporary file to save the uploaded PDF\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmp_file:\n",
    "            tmp_file.write(pdf_file.getvalue())\n",
    "            tmp_path = tmp_file.name\n",
    "        \n",
    "        # Open the PDF file\n",
    "        with open(tmp_path, 'rb') as file:\n",
    "            # Create a PDF reader object\n",
    "            pdf_reader = pypdf.PdfReader(file)\n",
    "            \n",
    "            # Extract text from each page\n",
    "            for page_num in range(len(pdf_reader.pages)):\n",
    "                page = pdf_reader.pages[page_num]\n",
    "                text += page.extract_text() + \"\\n\\n\"\n",
    "        \n",
    "        # Clean up the temporary file\n",
    "        os.unlink(tmp_path)\n",
    "        return text\n",
    "    except Exception as e:\n",
    "        st.error(f\"Error extracting text from PDF: {e}\")\n",
    "        return \"\"\n",
    "\n",
    "# Create sample patient data\n",
    "def create_sample_patient_data():\n",
    "    # Sample patient data in FHIR format\n",
    "    patient_data = {\n",
    "        \"resourceType\": \"Bundle\",\n",
    "        \"type\": \"collection\",\n",
    "        \"entry\": [\n",
    "            {\n",
    "                \"resource\": {\n",
    "                    \"resourceType\": \"Patient\",\n",
    "                    \"id\": \"example-patient\",\n",
    "                    \"name\": [\n",
    "                        {\n",
    "                            \"given\": [\"John\"],\n",
    "                            \"family\": \"Smith\"\n",
    "                        }\n",
    "                    ],\n",
    "                    \"birthDate\": \"1970-05-15\",\n",
    "                    \"gender\": \"male\"\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"resource\": {\n",
    "                    \"resourceType\": \"Condition\",\n",
    "                    \"id\": \"condition-diabetes\",\n",
    "                    \"subject\": {\n",
    "                        \"reference\": \"Patient/example-patient\"\n",
    "                    },\n",
    "                    \"code\": {\n",
    "                        \"coding\": [\n",
    "                            {\n",
    "                                \"system\": \"http://snomed.info/sct\",\n",
    "                                \"code\": \"73211009\",\n",
    "                                \"display\": \"Diabetes mellitus type 2\"\n",
    "                            }\n",
    "                        ]\n",
    "                    },\n",
    "                    \"clinicalStatus\": {\n",
    "                        \"coding\": [\n",
    "                            {\n",
    "                                \"system\": \"http://terminology.hl7.org/CodeSystem/condition-clinical\",\n",
    "                                \"code\": \"active\",\n",
    "                                \"display\": \"Active\"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"resource\": {\n",
    "                    \"resourceType\": \"Condition\",\n",
    "                    \"id\": \"condition-hypertension\",\n",
    "                    \"subject\": {\n",
    "                        \"reference\": \"Patient/example-patient\"\n",
    "                    },\n",
    "                    \"code\": {\n",
    "                        \"coding\": [\n",
    "                            {\n",
    "                                \"system\": \"http://snomed.info/sct\",\n",
    "                                \"code\": \"38341003\",\n",
    "                                \"display\": \"Hypertension\"\n",
    "                            }\n",
    "                        ]\n",
    "                    },\n",
    "                    \"clinicalStatus\": {\n",
    "                        \"coding\": [\n",
    "                            {\n",
    "                                \"system\": \"http://terminology.hl7.org/CodeSystem/condition-clinical\",\n",
    "                                \"code\": \"active\",\n",
    "                                \"display\": \"Active\"\n",
    "                            }\n",
    "                        ]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"resource\": {\n",
    "                    \"resourceType\": \"MedicationRequest\",\n",
    "                    \"id\": \"medication-metformin\",\n",
    "                    \"subject\": {\n",
    "                        \"reference\": \"Patient/example-patient\"\n",
    "                    },\n",
    "                    \"medicationCodeableConcept\": {\n",
    "                        \"coding\": [\n",
    "                            {\n",
    "                                \"system\": \"http://www.nlm.nih.gov/research/umls/rxnorm\",\n",
    "                                \"code\": \"860975\",\n",
    "                                \"display\": \"Metformin 500 MG\"\n",
    "                            }\n",
    "                        ]\n",
    "                    },\n",
    "                    \"authoredOn\": \"2023-01-15\",\n",
    "                    \"status\": \"active\",\n",
    "                    \"dosageInstruction\": [\n",
    "                        {\n",
    "                            \"text\": \"Take 500mg twice daily with meals\"\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"resource\": {\n",
    "                    \"resourceType\": \"MedicationRequest\",\n",
    "                    \"id\": \"medication-lisinopril\",\n",
    "                    \"subject\": {\n",
    "                        \"reference\": \"Patient/example-patient\"\n",
    "                    },\n",
    "                    \"medicationCodeableConcept\": {\n",
    "                        \"coding\": [\n",
    "                            {\n",
    "                                \"system\": \"http://www.nlm.nih.gov/research/umls/rxnorm\",\n",
    "                                \"code\": \"314076\",\n",
    "                                \"display\": \"Lisinopril 10 MG\"\n",
    "                            }\n",
    "                        ]\n",
    "                    },\n",
    "                    \"authoredOn\": \"2023-02-10\",\n",
    "                    \"status\": \"active\",\n",
    "                    \"dosageInstruction\": [\n",
    "                        {\n",
    "                            \"text\": \"Take 10mg once daily\"\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"resource\": {\n",
    "                    \"resourceType\": \"Encounter\",\n",
    "                    \"id\": \"encounter-1\",\n",
    "                    \"subject\": {\n",
    "                        \"reference\": \"Patient/example-patient\"\n",
    "                    },\n",
    "                    \"period\": {\n",
    "                        \"start\": \"2024-01-10\"\n",
    "                    },\n",
    "                    \"type\": [\n",
    "                        {\n",
    "                            \"coding\": [\n",
    "                                {\n",
    "                                    \"system\": \"http://terminology.hl7.org/CodeSystem/encounter-type\",\n",
    "                                    \"code\": \"AMB\",\n",
    "                                    \"display\": \"Ambulatory\"\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    ],\n",
    "                    \"reasonCode\": [\n",
    "                        {\n",
    "                            \"coding\": [\n",
    "                                {\n",
    "                                    \"system\": \"http://snomed.info/sct\",\n",
    "                                    \"code\": \"73211009\",\n",
    "                                    \"display\": \"Diabetes follow-up\"\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"resource\": {\n",
    "                    \"resourceType\": \"Encounter\",\n",
    "                    \"id\": \"encounter-2\",\n",
    "                    \"subject\": {\n",
    "                        \"reference\": \"Patient/example-patient\"\n",
    "                    },\n",
    "                    \"period\": {\n",
    "                        \"start\": \"2024-02-15\"\n",
    "                    },\n",
    "                    \"type\": [\n",
    "                        {\n",
    "                            \"coding\": [\n",
    "                                {\n",
    "                                    \"system\": \"http://terminology.hl7.org/CodeSystem/encounter-type\",\n",
    "                                    \"code\": \"AMB\",\n",
    "                                    \"display\": \"Ambulatory\"\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    ],\n",
    "                    \"reasonCode\": [\n",
    "                        {\n",
    "                            \"coding\": [\n",
    "                                {\n",
    "                                    \"system\": \"http://snomed.info/sct\",\n",
    "                                    \"code\": \"38341003\",\n",
    "                                    \"display\": \"Hypertension follow-up\"\n",
    "                                }\n",
    "                            ]\n",
    "                        }\n",
    "                    ]\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "\n",
    "    # Save to file\n",
    "    with open('data/sample_patient.json', 'w') as f:\n",
    "        json.dump(patient_data, f, indent=2)\n",
    "    \n",
    "    return 'data/sample_patient.json'\n",
    "\n",
    "# Create sample guidelines\n",
    "def create_sample_guidelines():\n",
    "    # Sample diabetes guideline\n",
    "    diabetes_guideline = \"\"\"\n",
    "    # Diabetes Management Guidelines\n",
    "\n",
    "    ## Diagnosis\n",
    "    Diabetes mellitus is diagnosed based on one of the following criteria:\n",
    "    - Fasting plasma glucose  126 mg/dL (7.0 mmol/L)\n",
    "    - 2-hour plasma glucose  200 mg/dL (11.1 mmol/L) during OGTT\n",
    "    - A1C  6.5% (48 mmol/mol)\n",
    "    - Random plasma glucose  200 mg/dL (11.1 mmol/L) in patients with symptoms of hyperglycemia\n",
    "\n",
    "    ## Treatment Goals\n",
    "    - A1C < 7.0% for most adults\n",
    "    - Blood pressure < 140/90 mmHg\n",
    "    - LDL cholesterol < 100 mg/dL\n",
    "\n",
    "    ## Medication Recommendations\n",
    "    First-line therapy: Metformin (unless contraindicated)\n",
    "    Second-line options (based on patient factors):\n",
    "    - GLP-1 receptor agonists\n",
    "    - SGLT-2 inhibitors\n",
    "    - DPP-4 inhibitors\n",
    "    - Sulfonylureas\n",
    "    - Thiazolidinediones\n",
    "    - Insulin\n",
    "\n",
    "    ## Monitoring\n",
    "    - A1C testing: Every 3 months until target is reached, then at least twice per year\n",
    "    - Annual comprehensive foot examination\n",
    "    - Annual dilated eye examination\n",
    "    - Annual screening for albuminuria\n",
    "    - Lipid profile and kidney function tests annually\n",
    "    \"\"\"\n",
    "\n",
    "    # Sample hypertension guideline\n",
    "    hypertension_guideline = \"\"\"\n",
    "    # Hypertension Management Guidelines\n",
    "\n",
    "    ## Diagnosis\n",
    "    Hypertension is defined as:\n",
    "    - Systolic BP  130 mmHg or\n",
    "    - Diastolic BP  80 mmHg\n",
    "\n",
    "    ## Classification\n",
    "    - Normal: < 120/80 mmHg\n",
    "    - Elevated: 120-129/< 80 mmHg\n",
    "    - Stage 1: 130-139/80-89 mmHg\n",
    "    - Stage 2:  140/90 mmHg\n",
    "\n",
    "    ## Treatment Goals\n",
    "    - General population: < 130/80 mmHg\n",
    "    - Older adults ( 65 years): Target based on clinical judgment and patient preference\n",
    "\n",
    "    ## Medication Recommendations\n",
    "    First-line agents:\n",
    "    - Thiazide diuretics\n",
    "    - ACE inhibitors\n",
    "    - ARBs\n",
    "    - Calcium channel blockers\n",
    "\n",
    "    ## Monitoring\n",
    "    - Home BP monitoring is recommended\n",
    "    - Follow-up every 3-6 months for stable patients\n",
    "    - Annual screening for other cardiovascular risk factors\n",
    "    \"\"\"\n",
    "\n",
    "    # Save the guidelines to files\n",
    "    with open('data/guidelines/diabetes.txt', 'w') as f:\n",
    "        f.write(diabetes_guideline)\n",
    "\n",
    "    with open('data/guidelines/hypertension.txt', 'w') as f:\n",
    "        f.write(hypertension_guideline)\n",
    "    \n",
    "    return ['data/guidelines/diabetes.txt', 'data/guidelines/hypertension.txt']\n",
    "\n",
    "# Initialize the guideline retriever\n",
    "guideline_retriever = GuidelineRetriever(persist_directory=\"./chroma_db\")\n",
    "\n",
    "# Initialize the RAG workflow\n",
    "workflow = RAGWorkflow(guideline_retriever=guideline_retriever)\n",
    "\n",
    "# Initialize session state variables\n",
    "if 'patient_info' not in st.session_state:\n",
    "    st.session_state.patient_info = None\n",
    "if 'recommended_queries' not in st.session_state:\n",
    "    st.session_state.recommended_queries = None\n",
    "if 'case_summary' not in st.session_state:\n",
    "    st.session_state.case_summary = None\n",
    "if 'sample_data_created' not in st.session_state:\n",
    "    st.session_state.sample_data_created = False\n",
    "if 'sample_guidelines_created' not in st.session_state:\n",
    "    st.session_state.sample_guidelines_created = False\n",
    "\n",
    "# Streamlit app\n",
    "st.title(\"Patient Case Summary RAG Application\")\n",
    "\n",
    "# Create tabs\n",
    "tab1, tab2, tab3 = st.tabs([\"Upload Patient Data\", \"Add Guidelines\", \"Generate Summary\"])\n",
    "\n",
    "# Tab 1: Upload Patient Data\n",
    "with tab1:\n",
    "    st.header(\"Upload Patient Data\")\n",
    "    st.write(\"Upload a FHIR JSON file containing patient data.\")\n",
    "    \n",
    "    # Option to create sample data\n",
    "    if not st.session_state.sample_data_created:\n",
    "        if st.button(\"Create Sample Patient Data\"):\n",
    "            sample_file = create_sample_patient_data()\n",
    "            st.session_state.sample_data_created = True\n",
    "            st.success(f\"Sample patient data created at {sample_file}\")\n",
    "    \n",
    "    # File uploader\n",
    "    uploaded_file = st.file_uploader(\"Upload FHIR JSON file\", type=[\"json\"])\n",
    "    \n",
    "    if uploaded_file is not None:\n",
    "        # Save the uploaded file to a temporary location\n",
    "        with tempfile.NamedTemporaryFile(delete=False, suffix='.json') as tmp_file:\n",
    "            tmp_file.write(uploaded_file.getvalue())\n",
    "            tmp_path = tmp_file.name\n",
    "        \n",
    "        try:\n",
    "            # Parse the patient data\n",
    "            patient_info = parse_synthea_patient(tmp_path)\n",
    "            st.session_state.patient_info = patient_info\n",
    "            \n",
    "            # Display patient information\n",
    "            st.subheader(\"Patient Information\")\n",
    "            st.write(f\"**Name:** {patient_info.given_name} {patient_info.family_name}\")\n",
    "            st.write(f\"**Birth Date:** {patient_info.birth_date}\")\n",
    "            st.write(f\"**Gender:** {patient_info.gender}\")\n",
    "            \n",
    "            st.subheader(\"Conditions\")\n",
    "            for condition in patient_info.conditions:\n",
    "                st.write(f\"- {condition.display} (Status: {condition.clinical_status})\")\n",
    "            \n",
    "            st.subheader(\"Current Medications\")\n",
    "            for med in patient_info.current_medications:\n",
    "                st.write(f\"- {med.name}\")\n",
    "                if med.instructions:\n",
    "                    st.write(f\"  Instructions: {med.instructions}\")\n",
    "            \n",
    "            st.subheader(\"Recent Encounters\")\n",
    "            for encounter in patient_info.recent_encounters[:3]:  # Show only 3 most recent\n",
    "                reason = encounter.reason_display or encounter.type_display or \"Unknown\"\n",
    "                st.write(f\"- {encounter.date}: {reason}\")\n",
    "            \n",
    "            # Generate queries\n",
    "            query_generator = QueryGenerator()\n",
    "            recommended_queries = query_generator.generate_queries(patient_info)\n",
    "            st.session_state.recommended_queries = recommended_queries\n",
    "            \n",
    "        except Exception as e:\n",
    "            st.error(f\"Error parsing patient data: {str(e)}\")\n",
    "        \n",
    "        # Clean up the temporary file\n",
    "        os.unlink(tmp_path)\n",
    "    \n",
    "    # Use sample data\n",
    "    elif st.session_state.sample_data_created:\n",
    "        if st.button(\"Use Sample Patient Data\"):\n",
    "            try:\n",
    "                # Parse the sample patient data\n",
    "                patient_info = parse_synthea_patient('data/sample_patient.json')\n",
    "                st.session_state.patient_info = patient_info\n",
    "                \n",
    "                # Display patient information\n",
    "                st.subheader(\"Patient Information\")\n",
    "                st.write(f\"**Name:** {patient_info.given_name} {patient_info.family_name}\")\n",
    "                st.write(f\"**Birth Date:** {patient_info.birth_date}\")\n",
    "                st.write(f\"**Gender:** {patient_info.gender}\")\n",
    "                \n",
    "                st.subheader(\"Conditions\")\n",
    "                for condition in patient_info.conditions:\n",
    "                    st.write(f\"- {condition.display} (Status: {condition.clinical_status})\")\n",
    "                \n",
    "                st.subheader(\"Current Medications\")\n",
    "                for med in patient_info.current_medications:\n",
    "                    st.write(f\"- {med.name}\")\n",
    "                    if med.instructions:\n",
    "                        st.write(f\"  Instructions: {med.instructions}\")\n",
    "                \n",
    "                st.subheader(\"Recent Encounters\")\n",
    "                for encounter in patient_info.recent_encounters[:3]:  # Show only 3 most recent\n",
    "                    reason = encounter.reason_display or encounter.type_display or \"Unknown\"\n",
    "                    st.write(f\"- {encounter.date}: {reason}\")\n",
    "                \n",
    "                # Generate queries\n",
    "                query_generator = QueryGenerator()\n",
    "                recommended_queries = query_generator.generate_queries(patient_info)\n",
    "                st.session_state.recommended_queries = recommended_queries\n",
    "                \n",
    "            except Exception as e:\n",
    "                st.error(f\"Error parsing sample patient data: {str(e)}\")\n",
    "\n",
    "# Tab 2: Add Guidelines\n",
    "with tab2:\n",
    "    st.header(\"Add Guidelines\")\n",
    "    \n",
    "    # Option to create sample guidelines\n",
    "    if not st.session_state.sample_guidelines_created:\n",
    "        if st.button(\"Add Sample Guidelines\"):\n",
    "            sample_files = create_sample_guidelines()\n",
    "            num_chunks = guideline_retriever.add_guidelines('data/guidelines')\n",
    "            st.session_state.sample_guidelines_created = True\n",
    "            st.success(f\"Sample guidelines created and added to the knowledge base ({num_chunks} chunks).\")\n",
    "    \n",
    "    # Option 1: Enter guideline text\n",
    "    st.subheader(\"Option 1: Enter Guideline Text\")\n",
    "    guideline_title = st.text_input(\"Guideline Title\")\n",
    "    guideline_text = st.text_area(\"Guideline Text\", height=200)\n",
    "    \n",
    "    if st.button(\"Add Guideline Text\"):\n",
    "        if guideline_title and guideline_text:\n",
    "            metadata = {\"title\": guideline_title}\n",
    "            num_chunks = guideline_retriever.add_guideline_text(guideline_text, metadata)\n",
    "            st.success(f\"Successfully added guideline '{guideline_title}' ({num_chunks} chunks) to the knowledge base.\")\n",
    "        else:\n",
    "            st.error(\"Please enter both a title and text for the guideline.\")\n",
    "    \n",
    "    # Option 2: Upload guideline files\n",
    "    st.subheader(\"Option 2: Upload Guideline Files\")\n",
    "    st.write(\"Upload text files or PDF files containing guidelines.\")\n",
    "    \n",
    "    uploaded_files = st.file_uploader(\"Upload Files\", type=[\"txt\", \"pdf\"], accept_multiple_files=True)\n",
    "    \n",
    "    if uploaded_files and st.button(\"Process Files\"):\n",
    "        # Create a temporary directory\n",
    "        with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "            guidelines_dir = os.path.join(tmp_dir, 'guidelines')\n",
    "            os.makedirs(guidelines_dir, exist_ok=True)\n",
    "            \n",
    "            # Process each file\n",
    "            for uploaded_file in uploaded_files:\n",
    "                if uploaded_file.name.lower().endswith('.pdf'):\n",
    "                    # Extract text from PDF\n",
    "                    st.write(f\"Processing PDF: {uploaded_file.name}\")\n",
    "                    text = extract_text_from_pdf(uploaded_file)\n",
    "                    \n",
    "                    if text:\n",
    "                        # Save the extracted text to a file\n",
    "                        txt_filename = os.path.splitext(uploaded_file.name)[0] + \".txt\"\n",
    "                        txt_path = os.path.join(guidelines_dir, txt_filename)\n",
    "                        \n",
    "                        with open(txt_path, 'w', encoding='utf-8') as f:\n",
    "                            f.write(text)\n",
    "                        \n",
    "                        st.write(f\"Extracted {len(text.split())} words from {uploaded_file.name}\")\n",
    "                    else:\n",
    "                        st.error(f\"Failed to extract text from {uploaded_file.name}\")\n",
    "                \n",
    "                elif uploaded_file.name.lower().endswith('.txt'):\n",
    "                    # Save text file directly\n",
    "                    txt_path = os.path.join(guidelines_dir, uploaded_file.name)\n",
    "                    with open(txt_path, 'w', encoding='utf-8') as f:\n",
    "                        f.write(uploaded_file.getvalue().decode('utf-8'))\n",
    "            \n",
    "            # Add the guidelines to the vector store\n",
    "            num_chunks = guideline_retriever.add_guidelines(guidelines_dir)\n",
    "            st.success(f\"Successfully added {len(uploaded_files)} guideline files ({num_chunks} chunks) to the knowledge base.\")\n",
    "\n",
    "# Tab 3: Generate Summary\n",
    "with tab3:\n",
    "    st.header(\"Generate Case Summary\")\n",
    "    \n",
    "    if st.session_state.patient_info is not None:\n",
    "        # Display patient name\n",
    "        st.write(f\"Patient: {st.session_state.patient_info.given_name} {st.session_state.patient_info.family_name}\")\n",
    "        \n",
    "        # Display recommended queries\n",
    "        if st.session_state.recommended_queries is not None:\n",
    "            st.subheader(\"Recommended Queries\")\n",
    "            for i, query in enumerate(st.session_state.recommended_queries):\n",
    "                with st.expander(f\"Query {i+1}: {query.query}\"):\n",
    "                    st.write(f\"**Rationale:** {query.rationale}\")\n",
    "        \n",
    "        # Generate case summary\n",
    "        if st.button(\"Generate Case Summary\"):\n",
    "            with st.spinner(\"Generating case summary...\"):\n",
    "                case_summary = workflow.process_patient(st.session_state.patient_info)\n",
    "                st.session_state.case_summary = case_summary\n",
    "        \n",
    "        # Display case summary\n",
    "        if st.session_state.case_summary is not None:\n",
    "            st.subheader(\"Patient Summary\")\n",
    "            st.write(st.session_state.case_summary.patient_summary)\n",
    "            \n",
    "            st.subheader(\"Guideline Recommendations\")\n",
    "            st.write(st.session_state.case_summary.guideline_recommendations)\n",
    "            \n",
    "            st.subheader(\"Care Gaps\")\n",
    "            st.write(st.session_state.case_summary.care_gaps)\n",
    "            \n",
    "            st.subheader(\"Next Steps\")\n",
    "            st.write(st.session_state.case_summary.next_steps)\n",
    "            \n",
    "            # Option to download the summary\n",
    "            summary_text = f\"\"\"\n",
    "            # Patient Case Summary\n",
    "            \n",
    "            ## Patient Summary\n",
    "            {st.session_state.case_summary.patient_summary}\n",
    "            \n",
    "            ## Guideline Recommendations\n",
    "            {st.session_state.case_summary.guideline_recommendations}\n",
    "            \n",
    "            ## Care Gaps\n",
    "            {st.session_state.case_summary.care_gaps}\n",
    "            \n",
    "            ## Next Steps\n",
    "            {st.session_state.case_summary.next_steps}\n",
    "            \"\"\"\n",
    "            \n",
    "            st.download_button(\n",
    "                label=\"Download Case Summary\",\n",
    "                data=summary_text,\n",
    "                file_name=\"case_summary.md\",\n",
    "                mime=\"text/markdown\"\n",
    "            )\n",
    "    else:\n",
    "        st.info(\"Please upload patient data in the 'Upload Patient Data' tab first.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion\n",
    "\n",
    "This notebook provides a complete implementation of a RAG application for generating patient case summaries using open-source tools. The application extracts key details from patient data, retrieves relevant clinical guidelines, and generates comprehensive case summaries with recommendations.\n",
    "\n",
    "### Key Components\n",
    "\n",
    "1. **Patient Data Parser**: Extracts patient information from FHIR bundles\n",
    "2. **PDF Processor**: Extracts text from PDF files\n",
    "3. **Guideline Retriever**: Handles the storage and retrieval of medical guidelines using a vector database\n",
    "4. **Query Generator**: Generates queries for retrieving relevant medical guidelines\n",
    "5. **RAG Workflow**: Ties everything together to process patient data and generate case summaries\n",
    "6. **Interactive Interface**: Provides a user-friendly interface for interacting with the application\n",
    "\n",
    "### Usage\n",
    "\n",
    "1. Upload patient data in FHIR JSON format\n",
    "2. Add medical guidelines via text input or file upload (including PDF files)\n",
    "3. Generate case summaries with recommendations based on the patient data and guidelines\n",
    "\n",
    "This implementation demonstrates how to build a fully functional RAG application using only open-source, free resources."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
